\documentclass{article}
\usepackage[polish]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{pgfplots}

\begin{document}

\title{Współczesne Metody Heurystyczne - Projekt}
\author{
    Piotr Doniec \texttt{pdoniec@elka.pw.edu.pl}
    \and
    Łukasz Trzaska \texttt{ltrzaska@elka.pw.edu.pl}\\
    Wydział Elektroniki i Technik Informacyjnych,\\
    Politechnika Warszawska,\\
}

\date{\today}
\maketitle

\section{Wstęp}
\subsection{Treść zadania}
Celem projektu jest implementacja matody symulowanego wyżarzania (ang. simulated annealing - SA) w kilku wariantach do doboru wartości parametrów jąder przekształcenia w zadaniu klasyfikacyjnym. Wyznacznikiem jakości klasyfikacji jest ilość popełnianych błędów. Otrzymane wyniki należy porównać z metodą pełnego przeglądu.

\subsection{Symulowane wyżarzanie}
Symulowane wyżarzanie to rodzaj algorytmu poszukującego rozwiązania problemu optymalizacyjnego. Jest to algorytm heurystyczny, zatem znalezione rozwiązanie nie jest optymalne, a jedynie do niego zbliżone. Innymi przykładami algorytmów heurytycznych stosowanymi do optymalizacji jest rodzina algorytmów ewolucyjnych, Multistart, Adaptive Random Search.\linebreak
Symulowane wyżarzanie często wykorzystywane, jest gdy przestrzeń rozwiązań jest dyskretna. Najpowszechniejszym przykładem zadania, w który zastosowanie znajduje SA jest TSP (ang. Travelling Salesman Problem). Idea działania SA pochodzi z metalurgii i po raz pierwszy została opisana w 1953 roku. Pod wpływem wysokiej temperatury cząstki, atomy uwalniają się z pozycji, a oddając energię w czasie kontrolowanego schładzania rozkładają się w sposób bardziej systematyczny, przyjmując mniejszą wewnętrzną energię. Bazując na podobnych założeniach zaproponowano metodę symulowanego wyżarzania do rozwiązywania zadań optymalizacyjnych. \linebreak Algorytm znalazł szerokie zastosowanie począwszy od kolorowania i podziału grafu aż do optymalizacji rozlokowania układów elektronicznych, rekonstrukcji obrazu i geofizyki. Powszechność metody wynika głównie z łatwości implementacji w celu rozwiązania konkretnego zadania optymalizacyjnego, braku sczególnych wymagań dotyczących analizowanej / optymalizowanej funkcji a ponadto dowiedziono, że SA asymptotycznie dąży do globalnego minimum \cite{varts00}. Dodatową cechą algorytmu jest unikanie pułapek związanymi z minimami lokalnymi . Dzieje się tak, gdyż w określonych przypadkach, SA zezwala na przyjęcie gorszego rozwiązania niż aktualnie najlepsze.

\subsubsection{Ogólny opis algorytmu}
Algorytm symulowanego wyżarzania łatwo rozpatrywać dzieląc na 4 fazy: generowanie nowego, następnego stanu, sprawdzenie warunku akceptacji, redukcja parametrów sterujących, sprawdzenie warunku stopu.
    \begin{algorithm}
        \caption{Generyczna postać algorytmu symulowanego wyżarzania}
        \begin{algorithmic}
        \WHILE{warunek stopu nie osiągnięty}
            \FOR{$j = 1 \to N_c^k $}
                \STATE Generowanie nowego stanu
                \STATE Ewaluacja kryterium akceptacji
            \ENDFOR
            \STATE Uaktualnienie $N_c^k$
            \STATE Redukcja parametru sterującego
        \ENDWHILE
        \end{algorithmic}
    \end{algorithm}
    
\paragraph{Generowanie nowego stanu.}
Jest to bardzo istotny etap. Sposób wytwarzania nowych punktów wpływa w oczywisty sposób na wydajność algorytmu. Po kilku iteracjach algorytmu, powinno się uzyskiwać coraz niższe wartości funkcji. Z tego powodu dopasowanie metody generowania punktów do problemu jest bardzo istotne z punktu widzenia działnia algorytmu. W przypadku TSP, proponowanym sposobem na wyznaczenie kolejnych stanów jest zamiana kolejności w losowo wybranej parze kolejnych miast na drodze komiwojażera.
\paragraph*{Punkt startowy} algorytmu jest często poprostu losowany. Jednakże, w wielu arytułach pojawiają się sugestie, aby dobrać początkowy stan po uprzedniej analizie problemu.

\paragraph{Kryterium akceptacji.}
Pozwala ono SA na uniknięcie pułapki związanej z minimum lokalnym, kiedy poszukiwane jest minimum globalne. Dodatkowo w każdej kolejnej iteracji, prawdopodobieństwo tego że nowe, ale gorsze rozwiązanie zostanie zaakceptowane jest coraz mniejsze. Z tego wynika, że pod koniec działania algorytm koncentruje się na poprawianiu precyzji uzyskanego wyniku.
Najczęściej stosowanym kryterium akceptacji jest kryterium Metropolisa.

\[
  t^{k+1} = \left\{
  \begin{array}{l l}
    y & \quad \textrm{if $\tau \leq A_{{t^k}y}(c^k) $}\\
    t^k & \quad \textrm{wpp.}\\
  \end{array} \right.
\]

\[
A_{{t^k}y}(c^k) = min(1, \exp(-\frac{g(t^k)-g(y)}{c^k}) 
\]
, gdzie: \\ 
        $ t^k $ to aktualny stan, oszacowanie globalnego minimum, \\ 
        $ y $ jest nowym punktem, kandydatem, \\ 
        $\tau$ wartość wylosowana z przdziału jednostajnego $U(0,1)$, \\
        $ A_{{t^k}y}(c^k) $ kryterium Metropolisa \\

Większość vartiantów symulowanego wyżarzania korzysta z kryterium Metropolisa. Tyczy się to również obu modyfikacji opisanych w natępnych punktach.

    \paragraph{Redukcja parametru sterującego.}
    Funkcja malejąca $ c^k $ jest nazywana parametrem sterującym lub harmonogramem schładzania. W celu uzyskania wydajnego algorytmu początkowa wartość parametru sterującego powinna być wystarczająco wysoka by przeszukać regiony zawierające potencjalne rozwiązanie, ale jednocześnie nie przesadzono, bo spowoduje to spowolnienie algorytmu. Z tego powodu dobra wartość początkowa jest praktycznie niemożliwa do oszacowania bez żadnej analizy problemu. 

    \paragraph{Warunek stopu.}
    Istnieje wiele różnych warunków stopu do zastasowania w przypadku symulowanego wyżarzania. Wszystkie sprowadzają się do prostego pomysłu, że algorytm powinien się zatrzrymać jeśli ,,materiał'' zamarzł i mimo zmiany temperatury nie dostrzega się zmiany w rozwiązaniu. Przykładowym warunkiem stopu może być określona liczba iteracji lub osiągnięcie dolnej granicy parametru sterującego. Innym pomysłem jest zatrzymanie wyżarzania, kiedy kolejne $ N $ iteracji nie przynosi zmiany wyniku.

\subsubsection{Wariant Boltzmana}
W wariantcie Boltzmanna, nazywanym również SSA (ang. Standard Simulated Annealing), wykorzystywane są kolejno następująca funkcja generowania nowych punktów i harmonogram schładzania:

\[
g(\Delta x) = (2\pi T)^{-\frac{D}{2}}\exp(-\frac{({\Delta t}^2)}{2T})
\]

\[
T(k) = \frac{T_0}{lnk}
\]

,gdzie \\
    $ \Delta t_k = t_{k+1} - t_k $, to różnica między aktualnym i poprzednim stanem  \\
    $ k $, kwant czasu

\subsubsection{Wariant FSA}
Wariant wyróżnia się nie tylko inną metodą generowania nowego stanu, ale także inną funkcją zmiany temperatury. Na bazie FSA powstały kolejne modyfikacje SA. Najpierw było to VFSA (ang. Very Fast Simulated Annealing ) a potem ASA (ang. Adaptive Simulated Annealing). Ostatnia pozycja charakteryzuje się zmianą parametrów  (tj. harmonogram chłodzenia, generacja kolejnego stanu) w trakcie działania algorytmu. To sprawia, że algorytm jest bardziej wydajny i mniej wrażliwy na zdefiniowane przez użytkownika parametry.
\\ \\
Równania dla FSA: 
\[  T(t) = T_0/t  \]
\[  g(\Delta x ) = \frac{T}{(\Delta x^2 + T^2)^{\frac{D+1}{2}}}  \]

\subsection{SVM}
SVM (ang. Supporting Vector Machine) to koncepcja w statystyce oraz informatyce dla metod nadzorowanego uczenia maszyn w analizie danych i rozpoznawania wzorców na użytek algorytmów klasyfikacji i analizy regresji. Standardowo maszyna SVM jest w stanie przydzielić dane do jednej z dwóch klas. Czyni to algorytm SVM nieprobabilistycznym liniowym klasyfikatorem binarnym. Zadając zbiór danych trenujących, przyporządkowanych do jednej z kategorii, algorytm trenujący SVM buduje model, który przypisuje dane przykładowe do jednej z tych kategorii. Model ten jest reprezentacją danych przykładowych jako punktów w przestrzeni, odwzorowanej w taki sposób, aby dane z wydzielonych kategorii były oddzielone wyraźną przestrzenią, tak dużą jak to możliwe. Nowe dane są następnie odwzorowane na tą samą przestrzeń i przypisane do kategorii biorąc pod uwagę część przestrzeni w której się znajdują.

\subsubsection{Jądro przekształcenia}
Przy przekstrzałceniu danych treningowych na punkty w przestrzeni, która później służy do przypisywania kategorii dla danych testowych, można użyć kilku rodzajów jąder. W praktyce, na podstawie doświadczeń ze środowiskiem rozwiązania zadania MatLab, używa się poniższych:
\begin{enumerate}
\item liniowe,
\item kwadratowe,
\item wielomianowe,
\item tangens hiperboliczny,
\item rbf - funkcja charakterystyczna normalnego rozkładu Gausowska,
\item mlp - funkcja mnożnika perceptronu.
\end{enumerate}
Testy zostaną przeprowadzone dla jąder: wielomianowego, tangensa hiperbolicznego oraz rbf. W wynikach zwizualizowane zostaną te dane, które są najciekawsze pod kątem prezentacji różnorodności rozwiązania przedstawionego problemu.
\subsubsection{Wieloklasowy SVM}
Podział danych na dwie klasy jest często nie wystarczający. Aby rozszerzyć możliwości SVM o kategoryzację do kilku klas, wykorzystuje się kilka, niezależnie trenowanych binarnych SVM i definiuje strategię przydziału nowego wektora do jednej z istniejących klas. Jedną z takich strategii jest ,,one-versus-all''. Metoda polega na utworzeniu, w przypadku M klas, M binarnych maszyn SVM w których podział następuje między jedną z dostępnych klas a pozostałymi ( M - 1) klasami. Przydział testowego wektora do klasy odbywa się na zasadzie winner-takes-all.
Inne możliwe metody budowy wieloklasowego SVM to ,,one-against-one'' lub ,,DAGSVM''.
 
\pagebreak
\section{Założenie projektowe}
Cele postawione przed niniejszym projektem:
\begin{enumerate}
\item Porównanie wyników dla dwóch rodzajów jąder przekształcenia klasyfikacyjnego algorytmu SVM - zadane jako parametr wejściowy
\item Wykorzystanie metody symulowanego wyżarzania w dwóch wariantach: Bolztmanna oraz FSA - zadane jako parametr wejściowy
\item Implementacja rozwiązania oraz przeprowadzenie i wizualizacja wyników testowania w środowisku MATLAB
\item Na wejściu nadesłane dane trenujące i testowe, na wyjściu przydział wektorów do klas diagram popełnionych błędów
\item Kryterium stopu - określona liczba iteracji zadana jako parametr wejściowy
\end{enumerate}
\paragraph{Testowanie.}
Działanie dobranych parametrów dla jąder przekształceń przetestowane zostanie na przygotowanych wcześniej danych. Dane wejściowe treningowe, jak również dane testowe program przyjmnie w postaci wektorów liczb rzeczywistych, gdzie ostatnią składową wektora, będzie wartość liczbowa, wyznaczająca kategorię do której on przynależy. Wektory, zapisane będą w pliku tekstowym w postaci liczb zmiennoprzecinkowych o zapisie wykładniczym oddzielonych białym znakiem.
\paragraph{Złożoność obliczeniowa i czas wykonania.}
Szacowanie złożoności obliczeniowej oraz czasu wykonania dla całego rozwiązania dekomponuje się na złożoność i czas wykonania odpowiednio dla algorytmu wyżarzania oraz  algorytmu treningu klasyfikatora SVM, ponieważ w kroku, w którym ewaluowana jest wartość bieżącego znalezionego rozwiązania dla wyżarzania, trzeba będzie wykonać trening i testowanie danych przy użyciu SVM.
Będziemy posługiwać się pesymistyczną złożonością obliczeniową dla każdego z przypadków. Dla algorytmu symulowanego wyżarzania jest ona wielomianowa dla każdej składowej problemu, co w przypadku sumy złożoności przy doborze kilku parametrów pozostawia ją wielomianową. W przypadku algorytmu treningowego, parametrem złożoności klasyfikacji, będzie ilość danych wektorów wejściowych. Z dotychczasowej analizy dostępnych źródeł ustaliliśmy, że złożoność ta jest liniowa z ewentualnym doprecyzowaniem ilością wymiarów wektorów. W konkluzji, przyjąć można, że złożoność rożwiązania będzie wilomianowa.
\paragraph{Prezentacja wyników.}
Wyniki porównania jakości doboru parametrów jąder przekształceń zaprezentowane zostaną na wykresach obrazujących liczbę błędów klasyfikacji w zależności od wybranego jądra z podziałem na rodzaj danych (zredukowane i pełne) oraz podziałem na rodzaj symulowanego wyżarzania FSA (ang. Fast Simulated Annealing) oraz Boltzmann. Czasy wykonania dla poszczególnych typów jąder przekształceń nie będą zmienną, gdyż kryterium stopu obrane dla algorytmu jest kryterium czasu tzn. czas jest taki sam dla wszystkich porównywanych przypadków. 
\section{Środowisko realizacji}
Ze względu na bardzo dużą ilość matematyki w projekcie zdecydowaliśmy się na realizację projektu w programie MATLAB. Na korzyść wybory wpływa dostępność prostej maszyny SVM zaimplementowanej w Bioinformatics Toolbox oraz funkcji realizującej symulowane wyżarzanie o dużych możliwościach konfiguracyjnych dostępnej w Global Optimization Toolbox. Dzięki temu można skoncentrować się na rozwiązaniu problemu bez konieczności implementowania wszystkich algorytmów składowych.
\subsection{Symulowane wyżarzanie}
Dostępna w MATLAB funkcja \texttt{simulannealbnd} realizująca realizująca symulowane wyżarzanie, jest tak naprawdę jedynie szablonem, zapisana jest w sposób generyczny. Zanim zostanie wykorzystana, należy ją dostosować do własnych potrzeb i do rozwiązywanego problemu.
Do ustawiania parametrów wyżarzania korzysta się z \texttt{saoptimset}. Najważniejsze parametry z punktu widzenia projektu przedstawia Tablica \ref{tab:saoptimset} .

\begin{table}[h]
\caption{Parametry funkcji \texttt{simulannealbnd}}
\label{tab:saoptimset}
\begin{tabular}{|c|p{7cm}|}
\hline
Opcja & Opis \\ \hline \hline
\texttt{AcceptanceFcn} & Uchwyt do funkcji której algorytm użyje jako kryterium akceptacji \\ \hline
\texttt{AnnealingFcn} & Uchwyt do funkcji która zostanie użyta do generowania nowego punktu, kandydata \\ \hline
\texttt{DataType} & Typ danych \\ \hline
\texttt{InitialTemperature} & Początkowa temperatura \\ \hline
\texttt{MaxFunEvals} & Maximum number of objective function evaluations allowed \\ \hline
\texttt{MaxIter} & Maksymalna liczba iteracji \\ \hline
\texttt{PlotFcns} & Wyświetlanie wykresu w czasie wyżarzania \\ \hline
\texttt{TemperatureFcn} & Uchwyt do funkcji realizującej harmonogram schładzania \\ \hline
\texttt{TimeLimit} & Limit czasu działania algorytmu w sekundach \\ \hline
\end{tabular}
\end{table}

\subsection{SVM}
W celu zbudowania klasyfikatora wykorzystującego SVM należy wykorzystać 2 funkcje. Pierwsza z nich \texttt{svmtrain}  służy trenowaniu klasyfikatora. Jako parametry przyjmuje wektor danych i wektor klas. Możliwe jest tez podanie dodatkowych parametrów kontrolnych. Jednym z nich jest \texttt{kernelfunction} umożliwiający wskazanie funkcji wykonującej przkształcenie. Oprócz predefiniowanych wartości takich jak \texttt{linear}, \texttt{quadratic}, \texttt{polynomial}, można równiez wskazać uchwyt do samodzielnie zdefiniowanej funkcji.
Do klasyfikacji danych korzysta się z funkcji \texttt{svmclassify}. Parametry wejściowe to klasyfikator - rezultat \texttt{svmtrain} oraz dane które chcemy przydzielić do jednej z dwóch klas. Opcjonalnie można wygenerować wykres ilustrujący rezultat klasyfikacji.

\pagebreak
\section{Testowanie i wnioski}
\subsection{Kryterium stopu}
Dla wykonanych testów symulowanego wyżarzania, jako kryterium stopu wybrano ilość przeprowadzonych iteracji. W przypdaku ogólnego porównania różnych typów jąder i wariantów SA (ang. simulated annealing) wybrano arbitralnie 25 iteracji. W przypadku bardziej szczegółowych badań nad jądrem RBF, ilość powtórzeń została zwiększona do 50.
\subsection{Błędy a typ jądra}
\paragraph{}
Główne testy, pokazujące korelację liczby błędów do typu jądra, przeprowadzono dla dwóch zbiorów danych: \textit{zawężonych} i \textit{pełnych}.
\paragraph {Dane zawężone} Dla zróżnicowania badania skuteczności zastosowanej metody, test przeprowadzono najpierw na \textit{danych zawężonych} tzn. klasyfikowano wektory o zredukowanej do 3 liczbie wymiarów. Dane znajdują się w pliku: \textit{rs train7 short.csv}, a testujące odpowiednio w \textit{rs test7 short.csv}. Wynik eksperymentu przedstawiono na poniższym wykresie:
\pgfplotsset{width=6cm,compat=1.4}
\begin{center}
\begin{tikzpicture}
\begin{axis}[
ybar,
enlargelimits=0.4,
legend style={at={(0.5,-0.25)},
anchor=north,legend columns=-1},
ylabel={liczba błędów klasyfikacji},
symbolic x coords={FSA,Boltzmann,},
xtick=data,
nodes near coords,
nodes near coords align={vertical}
]
\addplot coordinates {(FSA,17) (Boltzmann,15)};
\addplot coordinates {(FSA,35) (Boltzmann,35)};
\addplot coordinates {(FSA,20) (Boltzmann,20)};
\addplot coordinates {(FSA,45)  (Boltzmann, 27)};
\legend{polynomial\(^3\), tanh, polynomial\(^2\), rbf}

\end{axis}
\end{tikzpicture}
\end{center}

Dla tego zestawu danych w wyniku uzyskano następujące wartości parametrów jąder:

\begin{center}
    \begin{tabular}{ | c | c | c | c | c | }
    \hline
    Typ SA & \textbf{Polynomial}$^{3}$ & \textbf{Tanh} & \textbf{Polynomial$^{2}$} & \textbf{rbf} \\ \hline
    FSA & 4.7243, -8.6634 & 0, 0 & -7.6178, 7.9733 & - \\ \hline
   Boltzmann & 8.4878, 9.9313 & 0, 0 & -8.4375, 7.9898 & 4.4031\\ \hline
    \end{tabular}
\end{center}

\paragraph {Dane pełne.}
Wyniki po trenowaniu na zbiorze \textit{rs\_train5\_no\_headers} i testowaniu na zbiorze \textit{rs\_test5\_no\_headers}.
\pgfplotsset{width=7cm,compat=1.4}
\begin{center}
\begin{tikzpicture}
\begin{axis}[
ybar,
enlargelimits=0.4,
legend style={at={(0.5,-0.25)},
anchor=north,legend columns=-1},
ylabel={liczba błędów klasyfikacji},
symbolic x coords={FSA,Boltzmann,},
xtick=data,
nodes near coords,
nodes near coords align={vertical}
]
\addplot coordinates {(FSA,11) (Boltzmann,11)};
\addplot coordinates {(FSA,11) (Boltzmann,11)};
\addplot coordinates {(FSA,34) (Boltzmann,34)};
\addplot coordinates {(FSA,21) (Boltzmann,22)};
\legend{polynomial\(^3\), polynomial\(^2\), tanh, rbf}

\end{axis}
\end{tikzpicture}
\end{center}

W wyniku przeprowadzonych obliczeń otrzymano następujące parametry jąder.
\begin{center}
    \begin{tabular}{ | c | c | c | c | c | }
    \hline
    Typ SA & \textbf{Polynomial}$^{3}$ & \textbf{Tanh} & \textbf{Polynomial$^{2}$} & \textbf{RBF} \\ \hline
    FSA & -7.1650, 7.1500 & 4.0350 , 4.0350 & -9.1107, 9.1107 & 7.4593  \\ \hline
   Boltzmann & 7.2506, 6.8868 & -9.990, 0.4460 & -9.7465, -2.2375 & -9\\ \hline
    \end{tabular}
\end{center}

\pgfplotsset{width=7cm,compat=1.4}
\paragraph{}
Wyniki po trenowaniu na zbiorze \textit{rs\_train7\_no\_headers} i testowaniu na zbiorze \textit{rs\_test7\_no\_headers}.
\begin{center}
\begin{tikzpicture}
\begin{axis}[
ybar,
enlargelimits=0.4,
legend style={at={(0.5,-0.25)},
anchor=north,legend columns=-1},
ylabel={liczba błędów klasyfikacji},
symbolic x coords={FSA,Boltzmann,},
xtick=data,
nodes near coords,
nodes near coords align={vertical}
]
\addplot coordinates {(FSA,16) (Boltzmann,16)};
\addplot coordinates {(FSA,15) (Boltzmann,15)};
\addplot coordinates {(FSA,35) (Boltzmann,35)};
\addplot coordinates {(FSA,22) (Boltzmann,22)};
\legend{polynomial\(^3\), polynomial\(^2\), tanh, rbf}

\end{axis}
\end{tikzpicture}
\end{center}

Dla tego zestawu danych w wyniku uzyskano następujące wartości parametrów jąder:

\begin{center}
    \begin{tabular}{ | c | c | c | c | c | }
    \hline
    Typ SA & \textbf{Polynomial}$^{3}$ & \textbf{Tanh} & \textbf{Polynomial$^{2}$} & \textbf{RBF} \\ \hline
    FSA & 1.1749, -1.1749 & 0, 0 & -0.0633, -5.8195 & -9.8351 \\ \hline
   Boltzmann & -9.7634, -2.1625 & 0, 0 & 2.3722, 9.7146 & 9.3501 \\ \hline
    \end{tabular}
\end{center}

\paragraph {Funkcje jąder wbudowane w środowisko MATLAB} 
Na poniższym wykresie zaprezentowano porównanie jakości jąder/parametrów dobranych metodą symulowanego wyżarzania z domyślnymi wartościami MATLAB. Wykorzystano zestaw danych \textit{rs\_train7\_no\_headers.txt} i \textit{rs\_test7\_no\_headers.txt}

\pgfplotsset{width=6cm,compat=1.4}
\begin{center}
\begin{tikzpicture}
\begin{axis}[
ybar,
enlargelimits=0.4,
legend style={at={(0.5,-0.25)},
anchor=north,legend columns=-1},
ylabel={liczba błędów klasyfikacji},
symbolic x coords={FSA},
xtick=data,
nodes near coords,
nodes near coords align={vertical}
]
\addplot coordinates {(FSA,16)};
\addplot coordinates {(FSA,35)};
\addplot coordinates {(FSA,32)};
\addplot coordinates {(FSA,35)};
\legend{polynomial3, quadratic, rbf, mlp}

\end{axis}
\end{tikzpicture}
\end{center}

Zgodnie ze oczekiwaniami, wartości domyślne nie zapewniają dobrej klasyfikacji danych. Celem poprawy, konieczne jest dobranie innych parametrów. W przypadku jądra RBF, MATLAB umożliwia wybranie jedynek parametru \textit{sigma}. W przypadku wbudowanegp jądra wielomianiowego możliwe jedynie jest wskazanie stopnia wielomianu. Zaimplementowane przez nas jądro i metoda SA bierze pod uwagę również pozostałe parametry, jednak w przypadku danych \textit{rs\_train7\_no\_headers.txt} i \textit{rs\_test7\_no\_headers.txt} nie ma to wpływu na ostateczny wynik.

\subsection{Jakość doboru parametrów a ilość iteracji}
\paragraph{}
Przeprowadzono również test pokazujący jakość doboru parametrów przekształcenia od ilości iteracji. Okazało się, że wpływu na tę jakość nie ma ani funkcja zmiany temperatury, ani też wybrana temperatura początkowa (stosowano wartości 100, 500 i 2000). Największy wpływ natomiast miała wybrana funkcja przekształcenia jądra. Dane w uśrednionej postaci prezentuje poniższy wykres:

\pgfplotsset{width=7cm,compat=1.4}
\begin{center}
\begin{tikzpicture}
\begin{axis}[
ybar,
enlargelimits=0.4,
legend style={at={(0.5,-0.64)},
anchor=north,legend columns=-1},
ylabel={ },
symbolic x coords={polynomial$^{3}$, polynomial$^{2}$, tanh},
xtick=data,
nodes near coords,
nodes near coords align={vertical},
x tick label style={rotate=90, anchor=east},
]
\addplot coordinates {(polynomial$^{3}$,16) (polynomial$^{2}$,16) (tanh,35)};
\addplot coordinates {(polynomial$^{3}$,7) (polynomial$^{2}$,10) (tanh,10)};
\legend{b\l{}\k{e}d\'ow, iteracji}

\end{axis}
\end{tikzpicture}
\end{center}

\subsection{Symulowane wyżarzanie a metoda pełnego przeglądu}
\paragraph{}
Poniższe wykresy prezentują ilość błędów w zależności od dobranych parametrów przy użyciu metody pełnego  przeglądu. Do tego testu użyto jądra przekształcenia RBF. W przypadku symulowanego wyżarzania warunkiem zakończenia było 50 iteracji. Metoda pełnego przeglądu obliczała ilość błędów dla każdej wartości parametru \textit{sigma} z przeziału <1,30) z krokiem 0,2.

Bez trudu można zauważyć, że SA spisuje się bardzo dobrze. Dla dostepnych danych, wynik symulowanego wyżarzania jest identyczny jak w przypadku metody pełnego przeglądu, co znaczy, że w tym przedziale jest to wartość optymalna. Czas działania również wpływa na korzyść SA - jest czasami wielokrotnie krótszy. 

Nie są to zaskakujące wyniki, trzeba natomiast pamiętać że SA pozwoliło uzyskać optymalne rozwiązanie dla tych konkretnych danych w tym konkretnym przedziale. Mimo że algorytm zawiera metodę unikania minimów lokalnych, to zawsze istnieje ryzyko, że się tam znajdzie.

\pgfplotsset{width=10cm, compat=1.4}
\begin{center}
\begin{tikzpicture}
\begin{axis} [
ylabel={liczba b\l{}\k{e}d\'ow},
xlabel={warto\'s\'c parametru przekszta\l{}cenia},
title = {Wynik fullsearch dla rs\_train7\_no\_headers.txt i rs\_test7\_no\_headers.txt}
]
\addplot+[const plot mark mid]
coordinates
{(1,32) (1.2,30)  (1.6, 30) (1.8, 28)
(2, 28) (2.8, 27)
(3, 27)  
(4, 27) (4.8, 27) 
(5, 26) (5.2, 24) (5.4, 25) (5.8, 25)
(6, 25) 
(7.6, 25) (7.8, 24)
(8, 24) (8.2, 23) 
(9.2, 23) (9.4, 22) (9.8, 22)
(10, 22) (10.2, 23) (10.8, 23)
(11, 24)
(12, 24)
(13, 24)
(14, 24)
(15, 24)
(16, 24)
(17, 24)
(18, 24)
(19, 24)
(20, 24) (20.8, 25)
(21, 25)
(21, 25)
(22, 25)
(23, 25) (23.2, 26)
(24, 26)
(25, 26)
(26, 26)
(27, 26)
(28, 26)
(29, 26)
(30, 26)
};
\addlegendentry{metoda pe\l{}nego przegl\k{a}du, 53 minuty}
\addplot+[red,const plot mark mid]
coordinates{
(9.9367, 22)
};
\addlegendentry{symulowane wy\.zarzanie, 25 minut}
\end{axis}
\end{tikzpicture}
\end{center}

\pgfplotsset{width=10cm, compat=1.4}
\begin{center}
\begin{tikzpicture}
\begin{axis} [
ylabel={liczba b\l{}\k{e}d\'ow},
xlabel={Temperatura},
title = {Wynik SA dla rs\_train7\_no\_headers.txt i rs\_test7\_no\_headers.txt},
x dir = reverse
]
\addplot+[sharp plot]
coordinates
{
(100, 32) (50, 25) (3.333333e+001, 25) (25, 24) (20, 24) (1.666667e+001, 24) (1.428571e+001, 22)(1.250000e+001, 26) (1.111111e+001, 24) (10, 23)(9.090909e+000, 23) (8.333333e+000, 23) (7.692308e+000, 24) (7.142857e+000, 24) (6.666667e+000, 26) (6.250000e+000, 24) (5.882353e+000, 24) (5.555556e+000, 24) (5.263158e+000, 24) (5, 24) (4.761905e+000, 24) (4.545455e+000, 24) (4.347826e+000, 24) (4.166667e+000, 24) (4, 25) (3.846154e+000, 24) (3.703704e+000, 24) (3.571429e+000, 24) (3.448276e+000, 24) (3.333333e+000, 24) (3.225806e+000, 24) (3.125000e+000, 24) (3.030303e+000, 24) (2.941176e+000, 24) (2.857143e+000, 24) (2.777778e+000, 24) (2.702703e+000, 24) (2.631579e+000, 24) (2.564103e+000, 24) (2.500000e+000, 24) (2.439024e+000, 24) (2.380952e+000, 24) (2.325581e+000, 24) (2.272727e+000, 24) (2.222222e+000, 24) (2.173913e+000, 24) (2.127660e+000, 24) (2.083333e+000, 24) (2.040816e+000, 24) (2, 24) (1.960784e+000, 24) (1.923077e+000, 24) (1.923077e+000, 24)
};
\addlegendentry{symulowane wy\.zarzanie, 25 minut}
\end{axis}
\end{tikzpicture}
\end{center}

\pgfplotsset{width=10cm, compat=1.4}
\begin{center}
\begin{tikzpicture}
\begin{axis} [
ylabel={Rozwiązanie},
xlabel={Temperatura},
title = {Przebieg SA dla rs\_train7\_no\_headers.txt i rs\_test7\_no\_headers.txt},
x dir = reverse
]
\addplot+[sharp plot]
coordinates
{
(100.0000,1.0000)
(50.0000,21.9966)
(33.3333,22.2992)
(25.0000,10.9922)
(20.0000,10.9922)
(16.6667,10.9922)
(14.2857, 9.9367)
(12.5000,24.2224)
(11.1111,11.7225)
(10.0000, 8.7094)
(9.0909, 8.7094)
(8.3333, 8.7094)
(7.6923,17.0427)
(7.1429,17.0427)
(6.6667,24.1856)
(6.2500,17.5189)
(5.8824,17.5189)
(5.5556,17.5189)
(5.2632,11.9634)
(5.0000,11.9634)
(4.7619,11.9634)
(4.5455, 7.2015)
(4.3478,11.7469)
(4.1667,11.7469)
(4.0000, 7.5802)
(3.8462,11.5802)
(3.7037,15.4264)
(3.5714,15.4264)
(3.4483,15.4264)
(3.3333,15.4264)
(3.2258,15.4264)
(3.1250,15.4264)
(3.0303,15.4264)
(2.9412,15.4264)
(2.8571,15.4264)
(2.7778,15.4264)
(2.7027,18.2042)
(2.6316,18.2042)
(2.5641,18.2042)
(2.5000,18.2042)
(2.4390,18.2042)
(2.3810,15.7652)
(2.3256,13.3842)
(2.2727,13.3842)
(2.2222,13.3842)
(2.1739,13.3842)
(2.1277,13.3842)
(2.0833,15.5119)
(2.0408,15.5119)
(2.0000,15.5119)
(1.9608,15.5119)
(1.9231,15.5119)
(1.9231,15.5119)
};
\end{axis}
\end{tikzpicture}
\end{center}

\pgfplotsset{width=10cm, compat=1.4}
\begin{center}
\begin{tikzpicture}
\begin{axis} [
ylabel={liczba b\l{}\k{e}d\'ow},
xlabel={warto\'s\'c parametru przekszta\l{}cenia},
title = {Wynik fullsearch dla rs\_train5\_no\_headers.txt i rs\_test5\_no\_headers.txt}
]
\addplot+[const plot mark mid]
coordinates
{(1,31) (1.2,31)  (1.6, 30) (1.8, 29)
(2, 28) (2.2, 27) (2.8, 26)
(3.4, 26) (3.6, 25) (3.8, 25)
(4, 24) (4.2, 22) 
(5.2, 22) (5.4, 21) (5.6, 21)
(6, 23) (6.8, 22)
(7, 21) (7.8, 24)
(8.8, 21)
(9, 22) (9.4, 22) (9.8, 22)
(16, 23)
(18, 23)
(19, 22)
(24, 22) (24.2, 23)
(24.6, 22)
(26.4, 23)
(30, 23)
};
\addlegendentry{metoda pe\l{}nego przegl\k{a}du, 95 minut}
\addplot+[red,const plot mark mid]
coordinates{
(23.7439, 22)
};
\addlegendentry{symulowane wy\.zarzanie, 19 minut}
\end{axis}
\end{tikzpicture}
\end{center}


\pgfplotsset{width=10cm, compat=1.4}
\begin{center}
\begin{tikzpicture}
\begin{axis} [
ylabel={liczba b\l{}\k{e}d\'ow},
xlabel={Temperatura},
title = {Wynik SA dla rs\_train5\_no\_headers.txt i rs\_test5\_no\_headers.txt},
x dir = reverse
]
\addplot+[sharp plot]
coordinates
{
(100, 31)
(50, 28 )
(3.333333e+001, 23 )
(25, 23 )
(20, 25 )
(1.666667e+001, 22 )
(1.428571e+001, 22 )
(1.250000e+001, 23 )
(1.111111e+001, 23 )
(10, 23 )
(9.090909e+000, 23 )
(8.333333e+000, 23 )
(7.692308e+000, 23 )
(7.142857e+000, 22 )
(6.666667e+000, 22 )
(6.250000e+000, 23 )
(5.882353e+000, 23 )
(5.555556e+000, 23 )
(5.263158e+000, 23 )
(5, 23 )
(4.761905e+000, 23 )
(4.545455e+000, 23 )
(4.347826e+000, 23 )
(4.166667e+000, 22 )
(4, 22 )
(3.846154e+000, 22 )
(3.703704e+000, 23 )
(3.571429e+000, 22 )
(3.448276e+000, 23 )
(3.333333e+000, 22 )
(3.225806e+000, 23 )
(3.125000e+000, 22 )
(3.030303e+000, 22 )
(2.941176e+000, 23 )
(2.857143e+000, 22 )
(2.777778e+000, 22 )
(2.702703e+000, 22 )
(2.631579e+000, 22 )
(2.564103e+000, 22 )
(2.500000e+000, 22 )
(2.439024e+000, 22 )
(2.380952e+000, 22 )
(2.325581e+000, 22 )
(2.272727e+000, 22 )
(2.222222e+000, 22 )
(2.173913e+000, 22 )
(2.127660e+000, 22 )
(2.083333e+000, 22 )
(2.040816e+000, 22 )
(2, 22 )
(1.960784e+000, 22 )
(1.923077e+000, 22 )
(1.923077e+000, 22 )
};
\addlegendentry{symulowane wy\.zarzanie, 19 minut}
\end{axis}
\end{tikzpicture}
\end{center}

\pgfplotsset{width=10cm, compat=1.4}
\begin{center}
\begin{tikzpicture}
\begin{axis} [
ylabel={Rozwiązanie},
xlabel={Temperatura},
title = {Przebieg SA dla rs\_train5\_no\_headers.txt i rs\_test5\_no\_headers.txt},
x dir = reverse
]
\addplot+[sharp plot]
coordinates
{
(100.0000,1.0000)
(50.0000,2.1322)
(33.3333,28.4968)
(25.0000,28.7439)
(20.0000,3.7439)
(16.6667,23.7439)
(14.2857,23.7439)
(12.5000,30.2085)
(11.1111,30.3651)
(10.0000,30.6826)
(9.0909,30.6826)
(8.3333,30.6826)
(7.6923,22.3492)
(7.1429,22.3492)
(6.6667,22.3492)
(6.2500,29.0159)
(5.8824,29.1001)
(5.5556,29.1001)
(5.2632,30.4727)
(5.0000,30.4727)
(4.7619,30.8947)
(4.5455,26.1328)
(4.3478,21.5874)
(4.1667,21.5874)
(4.0000,21.5874)
(3.8462,21.5874)
(3.7037,17.7412)
(3.5714,21.4449)
(3.4483,17.8735)
(3.3333,14.4252)
(3.2258,17.7585)
(3.1250,20.9843)
(3.0303,20.9843)
(2.9412,17.9540)
(2.8571,20.8952)
(2.7778,20.8952)
(2.7027,20.8952)
(2.6316,20.8952)
(2.5641,23.5268)
(2.5000,23.5268)
(2.4390,23.5268)
(2.3810,21.0878)
(2.3256,21.0878)
(2.2727,21.0878)
(2.2222,21.0878)
(2.1739,21.0878)
(2.1277,21.0878)
(2.0833,21.0878)
(2.0408,21.0878)
(2.0000,19.0469)
(1.9608,19.0469)
(1.9231,19.0469)
(1.9231,19.0469)
};
\end{axis}
\end{tikzpicture}
\end{center}

\section{Dodatkowe spostrzeżenia}
\begin{itemize}
\item zarówno dla danych trenujących pełnych jak i zredukowanych, przy zastosowaniu metody wieloklasowej 
masznyny wektorów podpierających, jądrem które osiągnęło najmniejszy wskaźnik błędu jest jądro wielomianowe
2-go stopnia,
\item środowisko MATLAB umożliwia wygodną implementację opisywanej metody, jednak nie udostępnia wszystkich opcji, które
należałoby przeanalizować w realizacji projektu tj. użycie temperatury, jako kryterium stopu. Wydajność tego środowiska jest zadowalająca przy rozwiązaniu średniej wielkości problemów. W przypadku bardziej zlożonych zadań, należało by przemyślec implementację bardziej wydajnej metody multiklasowego SVM niż przedstawiona \textit{one-versus-one}. Warto również rozważyć implemetację całego algorytmu w języku kompilowalnym do kodu maszynowego. W takim wypadku MATLAB mógłby posłużyć do zbudowania prototypu i analizy poprawności,
\item w obu zestawach danych testujących, pojawiają się wektory które powinny zostac przypisane do klasy nie wystepującej w danych treningowych. Są to oczywiste, napewno nie jedyne, źródła błędów klasyfikacji
\end{itemize}

\begin{thebibliography}{9}
\bibitem{intr00}
Nello Cristianini, John Shawe-Taylor, \emph{An introduction to Support Vector Machines and other kernel-based learning methods}.
Cambridge University Press,
2000
\bibitem{varts00}
Ana I.P.N Pereira, Edite M.G.P. Fernandes, \emph{A study of simulated annealing variants}.
Braganca Polytechnic Institute, Bragaca, Portugal,
Minho University, Braga, Portugal.
\bibitem{nseo07}
Naotoshi Seo, \emph{A Comparison of Multi-class Support Vector Machine Methods for Face Recognition}. 
Department of Electrical and Computer Engineering, The University of Maryland, 
2007.
\bibitem{vfsa00}
Kou-Yuan Huang,Yueh-Hsun Hsieh, \emph{Very Fast Simulated Annealing for pattern detection and seismic applications}. Department of Computer Science, National Chiao Tung University, Hsinchu, Taiwan.
\bibitem{svmann07}
Shih-Wei Lin, Zne-Jung Lee, Shih-Chieh Chen, Tsung-Yuan Tseng, \emph{Parameter determination of support vector machine and feature selection using simulated annealing approach}. Department of Information Management, Chang Gung University, Department of Information Management, Huafan University, Department of Industrial Management, National Taiwan University of Science and Technology, 2007.
\bibitem{www1}
\emph{http://www.iue.tuwien.ac.at/phd/binder/node87.html}
\end{thebibliography}

\end{document}